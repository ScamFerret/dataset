{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.4: Information Used for Website Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading python modules\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = [\n",
    "    'AccessURL',\n",
    "    'ExtractText',\n",
    "    'ExtractHyperlink',\n",
    "    'GetSearchResult',\n",
    "    'SearchX/Twitter',\n",
    "    'SearchReddit',\n",
    "    'RetrieveWHOIS',\n",
    "    'RetrieveDNSRecord',\n",
    "    'RetrieveCertificate' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate actions from the analysis results\n",
    " def calculate_actions(path_list):\n",
    "    used_list = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    selected_list = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for path in path_list:\n",
    "        actions = list()\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        for dic in data:\n",
    "            actions.append(dic['action'])\n",
    "        for value in list(set(actions)):\n",
    "            if value not in key_list:\n",
    "                continue\n",
    "            used_list[key_list.index(value)]+=1\n",
    "\n",
    "        for action in actions:\n",
    "            if action not in key_list:\n",
    "                continue\n",
    "            selected_list[key_list.index(action)]+=1\n",
    "    return used_list, selected_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting keywords included in the basis for determining scam websites\n",
    "def count_keywords_separately(input_strings, keywords):  \n",
    "    counts = [[0] * len(keyword_list) for keyword_list in keywords]  \n",
    "    total_counts = [0]*len(keywords)\n",
    "    for input_string in input_strings:\n",
    "        done_keyword = []\n",
    "        temp_counts = [0]*len(keywords)\n",
    "        for category_idx, keyword_list in enumerate(keywords):  \n",
    "            for keyword_idx, keyword in enumerate(keyword_list):  \n",
    "                if keyword and keyword in input_string:\n",
    "                    if keyword not in done_keyword:\n",
    "                        counts[category_idx][keyword_idx] += 1\n",
    "                        done_keyword.append(keyword)\n",
    "                        if temp_counts[category_idx] <= 0:\n",
    "                            temp_counts[category_idx] +=1\n",
    "        for index, temp in enumerate(temp_counts):\n",
    "            total_counts[index] += temp\n",
    "    return total_counts, counts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 9: Selected Information Types and Keywords\n",
    "information_type = ['Certificate Information', 'Company Information', 'Contact Information', 'Domain Name', 'Payment Method', 'Privacy Information', 'Social Engineering', 'Unusual Price', 'User Review', 'Website Status']\n",
    "keywords = [\n",
    "    ['tls', 'certificate', 'https', 'ssl'],\n",
    "    ['company information', 'non-existent companies','non-existent company','physical address'],\n",
    "    ['email', 'phone number',' contact information','toll-free number'],\n",
    "    ['whois', 'registrant', 'privacy service', 'domain' ,'dns'],\n",
    "    ['payment', 'bitcoin', 'cryptocurrency'],\n",
    "    ['privacy policy', 'privacy notation', 'privacy policies', 'privacy protection'],\n",
    "    ['psychological', 'lure', 'urgency', 'unrealistic', 'phishing tactic', 'scam tactic', 'short timeframe'],\n",
    "    ['low price', 'discounts', 'free items', 'high return', 'guaranteed returns', 'free delivery', 'free shipping'],  \n",
    "    ['social media', 'feedback', 'review', 'twitter', 'reddit', 'complaint','report', 'discussion', 'forum', 'low trust score', 'negative', 'indicators', 'social platforms'],\n",
    "    ['update', 'copyright', 'outdated', 'up-to-date']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPT-4----------\n",
      "AccessURL 2724 99.95833333333334\n",
      "ExtractText 2723 99.0\n",
      "ExtractHyperlink 1018 40.458333333333336\n",
      "GetSearchResult 1797 68.04166666666667\n",
      "SearchX/Twitter 1060 43.583333333333336\n",
      "SearchReddit 1545 63.541666666666664\n",
      "RetrieveWHOIS 2479 99.5\n",
      "RetrieveDNSRecord 617 25.458333333333332\n",
      "RetrieveCertificate 1276 52.87500000000001\n",
      "----------GPT-3.5----------\n",
      "AccessURL 2417 99.0\n",
      "ExtractText 2398 95.33333333333334\n",
      "ExtractHyperlink 281 11.25\n",
      "GetSearchResult 51 2.125\n",
      "SearchX/Twitter 22 0.8750000000000001\n",
      "SearchReddit 12 0.5\n",
      "RetrieveWHOIS 1128 45.83333333333333\n",
      "RetrieveDNSRecord 51 2.125\n",
      "RetrieveCertificate 85 3.5416666666666665\n",
      "----------Gemini Pro----------\n",
      "AccessURL 2471 80.95833333333333\n",
      "ExtractText 3406 90.25\n",
      "ExtractHyperlink 1088 34.458333333333336\n",
      "GetSearchResult 552 17.708333333333336\n",
      "SearchX/Twitter 270 9.833333333333332\n",
      "SearchReddit 196 7.166666666666667\n",
      "RetrieveWHOIS 419 16.416666666666664\n",
      "RetrieveDNSRecord 129 5.0\n",
      "RetrieveCertificate 83 3.3333333333333335\n"
     ]
    }
   ],
   "source": [
    "# Table 7: Number of Tools Selected and Usage per LLM\n",
    "\n",
    "# GPT-4 results\n",
    "path_list = glob.glob('./gpt-4_results/classification_accuracy/*/*/*.json')\n",
    "used_list, selected_list = calculate_actions(path_list)\n",
    "print ('----------GPT-4----------')\n",
    "for key, selected, used in zip(key_list, selected_list, used_list):\n",
    "    print (key, selected, used/len(path_list)*100)\n",
    "\n",
    "# GPT-3.5 results\n",
    "path_list = glob.glob('./gpt-3.5_results/classification_accuracy/*/*/*.json')\n",
    "used_list, selected_list = calculate_actions(path_list)\n",
    "print ('----------GPT-3.5----------')\n",
    "for key, selected, used in zip(key_list, selected_list, used_list):\n",
    "    print (key, selected, used/len(path_list)*100)\n",
    "\n",
    "# Gemini Pro results\n",
    "path_list = glob.glob('./geminipro_results/classification_accuracy/*/*/*.json')\n",
    "used_list, selected_list = calculate_actions(path_list)\n",
    "print ('----------Gemini Pro----------')\n",
    "for key, selected, used in zip(key_list, selected_list, used_list):\n",
    "    print (key, selected, used/len(path_list)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GPT-4----------\n",
      "Certificate Information 770 32.083333333333336\n",
      "Company Information 307 12.791666666666668\n",
      "Contact Information 621 25.874999999999996\n",
      "Domain Name 1866 77.75\n",
      "Payment Method 339 14.124999999999998\n",
      "Privacy Information 379 15.791666666666668\n",
      "Social Engineering 796 33.166666666666664\n",
      "Unusual Price 1104 46.0\n",
      "User Review 1544 64.33333333333333\n",
      "Website Status 294 12.25\n",
      "----------GPT-3.5----------\n",
      "Certificate Information 43 1.7916666666666667\n",
      "Company Information 405 16.875\n",
      "Contact Information 227 9.458333333333334\n",
      "Domain Name 952 39.666666666666664\n",
      "Payment Method 315 13.125\n",
      "Privacy Information 229 9.541666666666666\n",
      "Social Engineering 279 11.625\n",
      "Unusual Price 686 28.583333333333332\n",
      "User Review 52 2.166666666666667\n",
      "Website Status 165 6.875000000000001\n",
      "----------Gemini Pro----------\n",
      "Certificate Information 28 1.1666666666666667\n",
      "Company Information 87 3.6249999999999996\n",
      "Contact Information 233 9.708333333333332\n",
      "Domain Name 157 6.541666666666666\n",
      "Payment Method 81 3.375\n",
      "Privacy Information 45 1.875\n",
      "Social Engineering 108 4.5\n",
      "Unusual Price 501 20.875\n",
      "User Review 90 3.75\n",
      "Website Status 69 2.875\n"
     ]
    }
   ],
   "source": [
    "# Table 8: Information in Reasons for Website Decision\n",
    "\n",
    "# GPT-4 results\n",
    "path_list = glob.glob('./gpt-4_results/classification_accuracy/*/*/*.json')\n",
    "reason_list = list()\n",
    "for path in path_list:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    reason_list.append(data[-1]['observation']['reason'].lower())\n",
    "total_counts, detailed_counts = count_keywords_separately(reason_list, keywords)\n",
    "\n",
    "print ('----------GPT-4----------')\n",
    "for information, count in zip(information_type, total_counts):\n",
    "    print (information, count, count/len(reason_list)*100)\n",
    "\n",
    "# GPT-3.5 results\n",
    "path_list = glob.glob('./gpt-3.5_results/classification_accuracy/*/*/*.json')\n",
    "reason_list = list()\n",
    "for path in path_list:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    reason_list.append(data[-1]['observation']['reason'].lower())\n",
    "total_counts, detailed_counts = count_keywords_separately(reason_list, keywords)\n",
    "\n",
    "print ('----------GPT-3.5----------')\n",
    "for information, count in zip(information_type, total_counts):\n",
    "    print (information, count, count/len(reason_list)*100)\n",
    "\n",
    "# Gemini Pro results\n",
    "path_list = glob.glob('./geminipro_results/classification_accuracy/*/*/*.json')\n",
    "reason_list = list()\n",
    "for path in path_list:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    reason_list.append(data[-1]['observation']['reason'].lower())\n",
    "total_counts, detailed_counts = count_keywords_separately(reason_list, keywords)\n",
    "\n",
    "print ('----------Gemini Pro----------')\n",
    "for information, count in zip(information_type, total_counts):\n",
    "    print (information, count, count/len(reason_list)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phishing_blog",
   "language": "python",
   "name": "phishing_blog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
